{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed2650d0",
   "metadata": {},
   "source": [
    "# Llama CPP Python: Run LLMs on Local Machine\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. **Generate Text**\n",
    "2. **Stream Response**\n",
    "3. **Pulling Model from HuggingFace**\n",
    "4. **Chat Completion**\n",
    "5. **Generate Embeddings**\n",
    "\n",
    "## Installation\n",
    "\n",
    "\n",
    "* **pip install llama-cpp-python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32b1a1c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T21:54:41.442784Z",
     "start_time": "2025-01-25T21:54:40.094009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'0.3.6'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import llama_cpp\n",
    "\n",
    "llama_cpp.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05a3c3e",
   "metadata": {},
   "source": [
    "## 1. Generate Text\n",
    "\n",
    "* **TheBloke/Llama-2-7B-Chat-GGUF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7e6a314",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_cpp.llama.Llama at 0x7f1cea183700>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from llama_cpp import Llama\n",
    "# \n",
    "# llm = Llama(model_path=\"./llama-2-7b-chat.Q4_K_S.gguf\", verbose=False)\n",
    "# \n",
    "# llm"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehul/Documents/Human-AI Research/AudioSimularca/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Llama-3.2-3B-Instruct-IQ3_M.gguf:   0%|          | 0.00/1.60G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68128e49dff746109b555d3350c62e47"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_load_from_file: using device Metal (Apple M3) - 5461 MiB free\n",
      "llama_model_loader: loaded meta data with 35 key-value pairs and 255 tensors from /Users/mehul/.cache/huggingface/hub/models--bartowski--Llama-3.2-3B-Instruct-GGUF/snapshots/5ab33fa94d1d04e903623ae72c95d1696f09f9e8/./Llama-3.2-3B-Instruct-IQ3_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Llama 3.2 3B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = Llama-3.2\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 3B\n",
      "llama_model_loader: - kv   6:                            general.license str              = llama3.2\n",
      "llama_model_loader: - kv   7:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
      "llama_model_loader: - kv   8:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\n",
      "llama_model_loader: - kv   9:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv  10:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv  11:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  17:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  18:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  19:                          general.file_type u32              = 27\n",
      "llama_model_loader: - kv  20:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  21:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  22:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  23:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  27:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  28:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  29:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - kv  30:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  31:                      quantize.imatrix.file str              = /models_out/Llama-3.2-3B-Instruct-GGU...\n",
      "llama_model_loader: - kv  32:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
      "llama_model_loader: - kv  33:             quantize.imatrix.entries_count i32              = 196\n",
      "llama_model_loader: - kv  34:              quantize.imatrix.chunks_count i32              = 125\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type q4_K:   59 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llama_model_loader: - type iq3_s:  137 tensors\n",
      "llm_load_vocab: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128001 '<|end_of_text|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.7999 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 131072\n",
      "llm_load_print_meta: n_embd           = 3072\n",
      "llm_load_print_meta: n_layer          = 28\n",
      "llm_load_print_meta: n_head           = 24\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 3\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 8192\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 131072\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 3B\n",
      "llm_load_print_meta: model ftype      = IQ3_S mix - 3.66 bpw\n",
      "llm_load_print_meta: model params     = 3.21 B\n",
      "llm_load_print_meta: model size       = 1.48 GiB (3.96 BPW) \n",
      "llm_load_print_meta: general.name     = Llama 3.2 3B Instruct\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: EOM token        = 128008 '<|eom_id|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOG token        = 128008 '<|eom_id|>'\n",
      "llm_load_print_meta: EOG token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: tensor 'token_embd.weight' (q6_K) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/29 layers to GPU\n",
      "llm_load_tensors:   CPU_Mapped model buffer size =  1518.09 MiB\n",
      ".................................................................................\n",
      "llama_new_context_with_model: n_seq_max     = 1\n",
      "llama_new_context_with_model: n_ctx         = 512\n",
      "llama_new_context_with_model: n_ctx_per_seq = 512\n",
      "llama_new_context_with_model: n_batch       = 512\n",
      "llama_new_context_with_model: n_ubatch      = 512\n",
      "llama_new_context_with_model: flash_attn    = 0\n",
      "llama_new_context_with_model: freq_base     = 500000.0\n",
      "llama_new_context_with_model: freq_scale    = 1\n",
      "llama_new_context_with_model: n_ctx_per_seq (512) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M3\n",
      "ggml_metal_init: picking default device: Apple M3\n",
      "ggml_metal_init: using embedded metal library\n",
      "ggml_metal_init: GPU name:   Apple M3\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple9  (1009)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = true\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  =  5726.63 MB\n",
      "ggml_metal_init: loaded kernel_add                                    0x11d04b2a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row                                0x11d04b4d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub                                    0x10b6fceb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub_row                                0x11d04b700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul                                    0x1051dd650 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_row                                0x11d04b930 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div                                    0x11b60e8d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div_row                                0x1051dd880 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f32                             0x1051ddc70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f16                             0x1051de060 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i32                             0x10b6fd0e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i16                             0x1051de290 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale                                  0x11b60ee30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale_4                                0x11b715950 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_clamp                                  0x11d04c440 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_tanh                                   0x105971460 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_relu                                   0x11d04c670 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sigmoid                                0x105971bf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu                                   0x1059720e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_4                                 0x1051ded90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick                             0x11d04ce00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick_4                           0x1051df290 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu                                   0x11d04d030 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu_4                                 0x1051dfba0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_elu                                    0x1051e0090 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16                           0x1051dfdd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16_4                         0x11b60f660 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32                           0x11b715fc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32_4                         0x11d04d420 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                          0x11d10bdb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf_8                        0x1051e0480 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f32                           0x1051e06b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                           0x1051e0aa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                          0x11d10c1a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                          0x10b6fd310 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_0                          0x105971e20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_1                          0x10b6fd540 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q8_0                          0x11b60f890 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                          0x1051e0e90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                          0x105972310 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                          0x1051e10c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                          0x1051e14b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                          0x11d04db90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xxs                       0x1051e18a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xs                        0x105972700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_xxs                       0x11d04ddc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_s                         0x13c919a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_s                         0x11d04dff0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_s                         0x10b6fd770 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_m                         0x105972930 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_nl                        0x105972b60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_xs                        0x10b6fd9a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_i32                           0x11d04e3e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm                               0x1051e1ad0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_group_norm                             0x1051e1ec0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_norm                                   0x11b7168f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_conv_f32                           0x105972d90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32                           0x10b6fdbd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32                         0x105972fc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32                         0x11d04e7d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_1row                    0x11d04ea00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_l4                      0x1059731f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f16                         0x11b716b20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_0_f32                        0x10b6fdfc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_1_f32                        0x10b6fe3b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_0_f32                        0x1059735e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_1_f32                        0x11d10cde0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q8_0_f32                        0x11d10d010 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_2                0x1051e2470 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_3                0x11d04ec30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_4                0x11d04ee60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_5                0x10b6fe7a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_2               0x11d04f090 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_3               0x11d04f2c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_4               0x11d04f4f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_5               0x1059739d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_2               0x10b6feb90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_3               0x10b6fef80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_4               0x1051e2860 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_5               0x105973dc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_2               0x11d04faa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_3               0x1051e2c50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_4               0x10b6ff1b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_5               0x1059741b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_2               0x1051e3200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_3               0x10b6ff3e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_4               0x11d04fe90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_5               0x105974760 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_2               0x10b6ff990 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_3               0x11d0500c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_4               0x1051e3430 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_5               0x1051e3820 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_2               0x10b6ffd80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_3               0x10cd04240 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_4               0x11d0504b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_5               0x10cd04470 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_2               0x10cd04950 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_3               0x11d0506e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_4               0x11d050910 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_5               0x10cd04d40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_2               0x1051e4470 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_3               0x10cd05220 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_4               0x1051e4860 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_5               0x105974d10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_2             0x11d050b40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_3             0x1051e4c50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_4             0x11d0510f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_5             0x1051e4e80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q2_K_f32                        0x11d051320 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q3_K_f32                        0x11d051550 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_K_f32                        0x11d051780 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_K_f32                        0x11d051b70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q6_K_f32                        0x1059752c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xxs_f32                     0x11d051f60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xs_f32                      0x11d052350 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_xxs_f32                     0x10cd05af0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_s_f32                       0x10cd05ee0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_s_f32                       0x10cd062d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_s_f32                       0x1051e5270 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_m_f32                       0x1051e5660 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_nl_f32                      0x1051e5a50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_xs_f32                      0x10cd06510 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f32_f32                      0x1051e5e40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f16_f32                      0x1051e6070 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_0_f32                     0x1051e6460 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_1_f32                     0x105975a30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_0_f32                     0x11d052900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_1_f32                     0x11d052b30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q8_0_f32                     0x1051e6850 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q2_K_f32                     0x10cd06ac0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q3_K_f32                     0x11d052f20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_K_f32                     0x11d053150 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_K_f32                     0x11d053540 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q6_K_f32                     0x1051e6a80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xxs_f32                  0x11d053930 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xs_f32                   0x1051e7030 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_xxs_f32                  0x11d053b60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_s_f32                    0x105975fe0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_s_f32                    0x10cd06eb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_s_f32                    0x10cd072a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_m_f32                    0x10cd074e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_nl_f32                   0x11d053f50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_xs_f32                   0x11d054180 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f32_f32                         0x11d0543b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f16_f32                         0x1051e75e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_0_f32                        0x11d0547a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_1_f32                        0x1051e7b90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_0_f32                        0x1051e7f80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_1_f32                        0x1051e81b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q8_0_f32                        0x10cd07a90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q2_K_f32                        0x105976590 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q3_K_f32                        0x105976980 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_K_f32                        0x105976bb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_K_f32                        0x10cd08040 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q6_K_f32                        0x10cd08430 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xxs_f32                     0x1051e85a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xs_f32                      0x1051e87d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_xxs_f32                     0x11d054d50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_s_f32                       0x11d054f80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_s_f32                       0x11d055370 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_s_f32                       0x1051e8a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_m_f32                       0x10cd089e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_nl_f32                      0x10cd08de0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_xs_f32                      0x11d055760 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f32_f32                      0x1051e8df0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f16_f32                      0x11d055990 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_0_f32                     0x1051e93a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_1_f32                     0x1051e9790 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_0_f32                     0x11d055bc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_1_f32                     0x1051e9b80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q8_0_f32                     0x11d055df0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q2_K_f32                     0x10cd09390 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q3_K_f32                     0x10cd095c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_K_f32                     0x1051ea2f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_K_f32                     0x11d056020 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q6_K_f32                     0x11d056250 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xxs_f32                  0x1051ea8a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xs_f32                   0x11d056480 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_xxs_f32                  0x105977320 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_s_f32                    0x105977710 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_s_f32                    0x1051eaad0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_s_f32                    0x1051eaec0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_m_f32                    0x10cd09ef0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_nl_f32                   0x11d056870 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_xs_f32                   0x105977940 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f32                          0x10cd0a530 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f16                          0x10cd0a920 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f32                          0x1051eb470 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f16                          0x11d056aa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f16                             0x11d056e90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f32                             0x10cd0ab50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f16                         0x10cd0aff0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f32                         0x10cd0b430 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f32_f32              0x11d057280 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f16_f32              0x11d057670 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_upscale_f32                            0x11d057a60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_f32                                0x11d057e50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_reflect_1d_f32                     0x105977b70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_timestep_embedding_f32                 0x1051eb860 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_arange_f32                             0x11d058240 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_asc                    0x1051eba90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_desc                   0x105978120 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_leaky_relu_f32                         0x105978830 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h64                 0x105978c20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h80                 0x11d058930 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h96                 0x1051ebe80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h112                0x1051ec0b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h128                0x11d058b60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h256                0x11d058d90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h64                0x1051ec880 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h80                0x10cd0bdb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h96                0x11d058fc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h112               0x10cd0c1a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h128               0x1051ecc70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h256               0x11d0593b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h64                0x11d0595e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h80                0x11d0599d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h96                0x11d059c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h112               0x11d059e30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h128               0x105979710 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h256               0x1051ed1e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h64                0x11d05a220 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h80                0x11d05a450 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h96                0x11d05a680 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h112               0x1051edae0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h128               0x1051eded0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h256               0x10cd0c680 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h64                0x11d05aa70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h80                0x11d05ae60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h96                0x1051ee460 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h112               0x11d05b090 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h128               0x11d05b2c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h256               0x10cd0cdf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h64                0x1051eea10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h80                0x1051eec40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h96                0x1051eee70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h112               0x11d05b4f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h128               0x11d05b720 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h256               0x1051ef420 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h128            0x1051ef650 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h128           0x11d05bcd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h128           0x11d05bf00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h128           0x11d05c130 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h128           0x11d05c360 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h128           0x11d05c590 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h256            0x11d05c7c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h256           0x1051efdc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h256           0x1051efff0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h256           0x1051f0220 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h256           0x105979e80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h256           0x10cd0dd20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_f32                                0x1051f0450 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_i32                                0x1051f0840 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                            0x11d05cf30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                            0x11d05d320 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f32                            0x1051f0c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                            0x1051f1020 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q8_0                           0x10cd0e190 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_0                           0x10597a0b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_1                           0x1051f1250 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_0                           0x1051f1640 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_1                           0x1051f1870 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_iq4_nl                         0x11d05da90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_concat                                 0x11d05dcc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqr                                    0x11d05e760 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqrt                                   0x11d05eed0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sin                                    0x11d05f640 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cos                                    0x11d05fdb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sum_rows                               0x1051f1c60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argmax                                 0x1051f2050 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_avg_f32                        0x1051f2440 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_max_f32                        0x10cd0e3c0 | th_max = 1024 | th_width =   32\n",
      "llama_kv_cache_init: kv_size = 512, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init:        CPU KV buffer size =    56.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   56.00 MiB, K (f16):   28.00 MiB, V (f16):   28.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   256.50 MiB\n",
      "llama_new_context_with_model: graph nodes  = 902\n",
      "llama_new_context_with_model: graph splits = 450 (with bs=512), 1 (with bs=1)\n",
      "Metal : EMBED_LIBRARY = 1 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | MATMUL_INT8 = 1 | DOTPROD = 1 | MATMUL_INT8 = 1 | ACCELERATE = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'quantize.imatrix.file': '/models_out/Llama-3.2-3B-Instruct-GGUF/Llama-3.2-3B-Instruct.imatrix', 'quantize.imatrix.chunks_count': '125', 'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- if strftime_now is defined %}\\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\\n    {%- else %}\\n        {%- set date_string = \"26 Jul 2024\" %}\\n    {%- endif %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n        {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n        {{- \\'\"parameters\": \\' }}\\n        {{- tool_call.arguments | tojson }}\\n        {{- \"}\" }}\\n        {{- \"<|eot_id|>\" }}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'tokenizer.ggml.eos_token_id': '128009', 'general.type': 'model', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.ggml.model': 'gpt2', 'llama.embedding_length': '3072', 'llama.vocab_size': '128256', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.attention.value_length': '128', 'llama.attention.head_count': '24', 'llama.attention.key_length': '128', 'llama.attention.head_count_kv': '8', 'general.finetune': 'Instruct', 'general.file_type': '27', 'llama.block_count': '28', 'general.size_label': '3B', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.feed_forward_length': '8192', 'general.quantization_version': '2', 'llama.rope.dimension_count': '128', 'general.license': 'llama3.2', 'quantize.imatrix.entries_count': '196', 'llama.context_length': '131072', 'general.architecture': 'llama', 'general.basename': 'Llama-3.2', 'llama.rope.freq_base': '500000.000000', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'general.name': 'Llama 3.2 3B Instruct'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- if strftime_now is defined %}\n",
      "        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n",
      "    {%- else %}\n",
      "        {%- set date_string = \"26 Jul 2024\" %}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "        {{- '\"parameters\": ' }}\n",
      "        {{- tool_call.arguments | tojson }}\n",
      "        {{- \"}\" }}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama.from_pretrained(\n",
    "\trepo_id=\"bartowski/Llama-3.2-3B-Instruct-GGUF\",\n",
    "\tfilename=\"Llama-3.2-3B-Instruct-IQ3_M.gguf\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-25T22:00:07.063895Z",
     "start_time": "2025-01-25T21:59:12.323676Z"
    }
   },
   "id": "cca405c22637a2de",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d90fe5c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T22:01:16.168580Z",
     "start_time": "2025-01-25T22:01:00.731365Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4353.81 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    14 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   151 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   15418.70 ms /   165 tokens\n"
     ]
    }
   ],
   "source": [
    "resp = llm(\"Q: Write a short paragraph introducing Elon Musk. A: \",\n",
    "           max_tokens=256,\n",
    "           stop=[\"Q:\", \"\\n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4879cdc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T22:01:24.117653Z",
     "start_time": "2025-01-25T22:01:24.100754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': 'cmpl-9894e8f6-a5f5-4929-b089-f670aa4792bf',\n 'object': 'text_completion',\n 'created': 1737842460,\n 'model': '/Users/mehul/.cache/huggingface/hub/models--bartowski--Llama-3.2-3B-Instruct-GGUF/snapshots/5ab33fa94d1d04e903623ae72c95d1696f09f9e8/./Llama-3.2-3B-Instruct-IQ3_M.gguf',\n 'choices': [{'text': \"2019 was a year of great change for Elon Musk, as he continued to push the boundaries of innovation and technological advancement. As the CEO of SpaceX and Tesla, Musk has revolutionized the electric vehicle industry with Tesla's success and made significant progress in establishing a human settlement on Mars, which is a major goal of SpaceX. Musk has also been a driving force behind the development of renewable energy systems and has made significant contributions to the field of artificial intelligence. His vision for the future is centered around making sustainable energy solutions and space travel accessible to humanity. With his relentless pace of innovation, Musk continues to be a leader in shaping the future of technology and sustainability. (Note: The response is based on his past achievements as of the year 2023) \",\n   'index': 0,\n   'logprobs': None,\n   'finish_reason': 'stop'}],\n 'usage': {'prompt_tokens': 14, 'completion_tokens': 152, 'total_tokens': 166}}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acc53ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Elon Musk is a South African-born entrepreneur, inventor, and business magnate known for his innovative ideas and ambitious ventures in various industries. He co-founded PayPal, which was later sold to eBay for $1.5 billion, and went on to found SpaceX and Tesla, revolutionizing the aerospace and electric vehicle sectors respectively. Musk has been instrumental in shaping the future of transportation, energy, and space exploration through his visionary leadership and technological advancements. With a unique ability to identify emerging trends and capitalize on them, he continues to inspire and influence the global business landscape as a pioneer of cutting-edge technologies and sustainable solutions.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad5e91e",
   "metadata": {},
   "source": [
    "## 2. Streaming Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa81d171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Llama._create_completion at 0x7f82b43a3e60>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = llm(\"Q: Write a short paragraph introducing Elon Musk. A: \",\n",
    "           max_tokens=256,\n",
    "           stop=[\"Q:\", \"\\n\"],\n",
    "           stream=True)\n",
    "\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f29ddedb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure, here is a short paragraph introducing Elon Musk:  Elon Musk is a South African-born entrepreneur and business magnate known for his innovative ideas and cutting-edge technology ventures. He is best known as the CEO of SpaceX and Tesla, Inc., where he has revolutionized the electric car industry and made space travel more accessible than ever before. With a net worth of over $200 billion, Musk has become one of the richest people in the world, and his vision for the future includes establishing a human settlement on Mars and developing sustainable energy solutions to combat climate change."
     ]
    }
   ],
   "source": [
    "for r in resp:\n",
    "    print(r[\"choices\"][0][\"text\"], end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14125cc3",
   "metadata": {},
   "source": [
    "## 3. Pulling Model from HuggingFace\n",
    "\n",
    "* **pip install huggingface-hub**\n",
    "\n",
    "By default from_pretrained will download the model to the **huggingface cache directory**, you can then manage installed model files with the **huggingface-cli tool**.\n",
    "\n",
    "* **TheBloke/Mistral-7B-v0.1-GGUF**\n",
    "* **TheBloke/Mistral-7B-Instruct-v0.2-GGUF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e1d15e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629c77519c434dc7bb0c34f4eee804b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mistral-7b-v0.1.Q4_K_S.gguf:   0%|          | 0.00/4.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "mistral = Llama.from_pretrained(repo_id=\"TheBloke/Mistral-7B-v0.1-GGUF\",\n",
    "                                filename=\"*Q4_K_S.gguf\",\n",
    "                                verbose=False\n",
    "                               ) \n",
    "\n",
    "resp = mistral(\"Q: Write a short paragraph introducing Elon Musk. A: \",\n",
    "           max_tokens=256,\n",
    "           stop=[\"Q:\", \"\\n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c1ee000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'cmpl-bf878ce0-865c-4bb5-a985-083dae3da9a6',\n",
       " 'object': 'text_completion',\n",
       " 'created': 1712553512,\n",
       " 'model': '/home/sunny/.cache/huggingface/hub/models--TheBloke--Mistral-7B-v0.1-GGUF/snapshots/d4ae605152c8de0d6570cf624c083fa57dd0d551/./mistral-7b-v0.1.Q4_K_S.gguf',\n",
       " 'choices': [{'text': '38 years old, Elon Musk is the founder and CEO of two leading high-tech companies in Silicon Valley; Tesla Motors and SpaceX. He has developed an electric sports car called TESLA ROADSTER which can reach speed upto 250 km per hour and accelerate from 0 to 100 km per hour within four seconds. In order to reach this speed it takes only 19 seconds for Tesla Roadster to go from 0 to 160 km per hour. Its top speed is about 370 km per hour.',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 16, 'completion_tokens': 125, 'total_tokens': 141}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926575ca",
   "metadata": {},
   "source": [
    "## 4. Chat Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d2cfd7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-3ebfd942-727b-4522-b274-7da696cdbb8f',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1712553589,\n",
       " 'model': './llama-2-7b-chat.Q4_K_S.gguf',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': \"  Ah, the visionary entrepreneur and innovator, Elon Musk! This man is truly a force to be reckoned with. With his piercing blue eyes and unruly mop of hair, he exudes an unmistakable air of ambition and drive. His sharp jawline and chiseled features give him a distinctly angular, futuristic look, as if he's ready to take on the world at any moment. But it's not just his physical appearance that sets him apart - it's his unwavering commitment to pushing the boundaries of technology and innovation. From revolutionizing the electric car industry with Tesla to making humanity a multiplanetary species with SpaceX, Elon Musk is a true pioneer in every sense of the word. With his unrelenting drive and unparalleled vision, he's changing the world one groundbreaking idea at a time.\"},\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 40, 'completion_tokens': 202, 'total_tokens': 242}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llama2_chat = Llama(model_path=\"./llama-2-7b-chat.Q4_K_S.gguf\", verbose=False) \n",
    "\n",
    "resp = llama2_chat.create_chat_completion(\n",
    "      messages = [\n",
    "          {\"role\": \"system\", \"content\": \"You are an assistant who perfectly describes individuals.\"},\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": \"Write a short paragraph introducing Elon Musk.\"\n",
    "          }\n",
    "      ]\n",
    ")\n",
    "\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fd477a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': \"  Ah, the visionary entrepreneur and innovator, Elon Musk! This man is truly a force to be reckoned with. With his piercing blue eyes and unruly mop of hair, he exudes an unmistakable air of ambition and drive. His sharp jawline and chiseled features give him a distinctly angular, futuristic look, as if he's ready to take on the world at any moment. But it's not just his physical appearance that sets him apart - it's his unwavering commitment to pushing the boundaries of technology and innovation. From revolutionizing the electric car industry with Tesla to making humanity a multiplanetary species with SpaceX, Elon Musk is a true pioneer in every sense of the word. With his unrelenting drive and unparalleled vision, he's changing the world one groundbreaking idea at a time.\"}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp[\"choices\"][0][\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8430b696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-1d13f224-51c3-4b94-b094-d9ea9dbefbf6',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1712553725,\n",
       " 'model': './llama-2-7b-chat.Q4_K_S.gguf',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': \"  Of course! Here's a rephrased version of my previous response:\\nElon Musk is a true pioneer in every sense of the word. With his piercing blue eyes and unruly mop of hair, he exudes an unmistakable air of ambition and drive. His sharp jawline and chiseled features give him a distinctly angular, futuristic look, as if he's ready to take on the world at any moment. But it's not just his physical appearance that sets him apart - it's his unwavering commitment to pushing the boundaries of technology and innovation. From revolutionizing the electric car industry with Tesla to making humanity a multiplanetary species with SpaceX, Elon Musk is changing the world one groundbreaking idea at a time. With his unrelenting drive and unparalleled vision, he's redefining what's possible and inspiring a new generation of thinkers and doers to join him on his mission to shape the future of humanity.\"},\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 263,\n",
       "  'completion_tokens': 228,\n",
       "  'total_tokens': 491}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_resp = llama2_chat.create_chat_completion(\n",
    "      messages = [\n",
    "          {\"role\": \"system\", \"content\": \"You are an assistant who perfectly describes individuals.\"},\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": \"Write a short paragraph introducing Elon Musk.\"\n",
    "          },\n",
    "          resp[\"choices\"][0][\"message\"],\n",
    "          {\n",
    "              \"role\": \"user\",\n",
    "              \"content\": \"Can you please rephrase your previous response?\"\n",
    "          }\n",
    "      ]\n",
    ")\n",
    "\n",
    "new_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2710ade6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': \"  Of course! Here's a rephrased version of my previous response:\\nElon Musk is a true pioneer in every sense of the word. With his piercing blue eyes and unruly mop of hair, he exudes an unmistakable air of ambition and drive. His sharp jawline and chiseled features give him a distinctly angular, futuristic look, as if he's ready to take on the world at any moment. But it's not just his physical appearance that sets him apart - it's his unwavering commitment to pushing the boundaries of technology and innovation. From revolutionizing the electric car industry with Tesla to making humanity a multiplanetary species with SpaceX, Elon Musk is changing the world one groundbreaking idea at a time. With his unrelenting drive and unparalleled vision, he's redefining what's possible and inspiring a new generation of thinkers and doers to join him on his mission to shape the future of humanity.\"}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_resp[\"choices\"][0][\"message\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c8dd75",
   "metadata": {},
   "source": [
    "## 5. Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bd9905c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'object': 'list',\n",
       " 'data': [{'object': 'embedding',\n",
       "   'embedding': [0.0031888174513418246,\n",
       "    -0.005338107164289213,\n",
       "    0.006393079045987913,\n",
       "    0.0028734011445135433,\n",
       "    -0.0261840098253423,\n",
       "    -0.002558798244006564,\n",
       "    -0.004504494117532277,\n",
       "    0.02568239549391057,\n",
       "    0.004633687720556026,\n",
       "    0.005226306354140698,\n",
       "    0.018378643351279995,\n",
       "    -0.008275122978843091,\n",
       "    0.009642914311027886,\n",
       "    0.004555599202739593,\n",
       "    0.006815992412490704,\n",
       "    -0.037152190183151614,\n",
       "    0.006974731048464214,\n",
       "    0.015619586233769092,\n",
       "    -0.016444021639667357,\n",
       "    -0.00929401890513487,\n",
       "    0.007328351262221089,\n",
       "    -0.024261604821921294,\n",
       "    -8.593770388037735e-06,\n",
       "    -0.014986538535901333,\n",
       "    0.01714968562025499,\n",
       "    0.00020696788598714944,\n",
       "    -0.009076134800973697,\n",
       "    -0.01066185304817868,\n",
       "    -0.005484406475604208,\n",
       "    -0.0017243357794410365,\n",
       "    0.005974833574089348,\n",
       "    -0.0005566141345380172,\n",
       "    -0.01825016242314457,\n",
       "    0.032526904975077486,\n",
       "    0.012484579262095804,\n",
       "    -0.016017254792195974,\n",
       "    -0.0017526646062518735,\n",
       "    0.005407783600137612,\n",
       "    0.0025367466223560737,\n",
       "    0.006672427959581075,\n",
       "    -0.0105842414936974,\n",
       "    -0.03524326103083447,\n",
       "    -0.013517823877358205,\n",
       "    -0.0183844233209043,\n",
       "    0.027237136810846,\n",
       "    -0.010135658232471532,\n",
       "    -0.011560756180534966,\n",
       "    0.0031065168486553944,\n",
       "    -0.016085116551279265,\n",
       "    -0.0039568472840294435,\n",
       "    -0.012374462681506689,\n",
       "    0.015136132772389054,\n",
       "    0.02242331056503734,\n",
       "    0.00845160898233592,\n",
       "    0.030920327262731313,\n",
       "    -0.0070217323350919856,\n",
       "    0.01757628726817629,\n",
       "    0.004242188962399079,\n",
       "    0.0056619813858875346,\n",
       "    -0.01004605359357983,\n",
       "    -0.026713021091915527,\n",
       "    -0.005234104981681894,\n",
       "    0.007328540133657924,\n",
       "    -0.006435638076421333,\n",
       "    -0.026980674582482718,\n",
       "    0.011071533829988248,\n",
       "    -0.014107204499029781,\n",
       "    -0.004136892380877986,\n",
       "    0.018393178897058795,\n",
       "    -0.018331623932994288,\n",
       "    0.015673678005964222,\n",
       "    -0.005142933465350211,\n",
       "    -0.0039093995053249946,\n",
       "    -0.0027720275486497977,\n",
       "    -0.02432851063970562,\n",
       "    -0.001984816814237285,\n",
       "    0.02292195331919621,\n",
       "    -0.022663774627214976,\n",
       "    0.0016206043125598468,\n",
       "    -0.008878774726281898,\n",
       "    0.03177110091641047,\n",
       "    0.003510420430955063,\n",
       "    0.0019204227347342797,\n",
       "    -0.03346283899682533,\n",
       "    -0.004226545874514682,\n",
       "    -0.0009073952958135383,\n",
       "    0.008508347976589723,\n",
       "    0.0026835352366067614,\n",
       "    0.011670610859398337,\n",
       "    -0.0073514721480326456,\n",
       "    -0.017325748048072145,\n",
       "    -0.003343993216530885,\n",
       "    0.0016442206711073666,\n",
       "    0.01106721446614213,\n",
       "    0.004692379393638119,\n",
       "    0.011130963360816908,\n",
       "    -0.004805390995611036,\n",
       "    -0.0013601740212229611,\n",
       "    -0.0035446132122224526,\n",
       "    -0.013906636128197616,\n",
       "    -0.009520480290814159,\n",
       "    0.0037571185096911537,\n",
       "    -0.02046963651019115,\n",
       "    0.029204742022873122,\n",
       "    5.721803123994068e-05,\n",
       "    0.009341238778972203,\n",
       "    -0.0010815462187756344,\n",
       "    -0.008291007822166636,\n",
       "    -0.002689771015965296,\n",
       "    0.005798223670933955,\n",
       "    0.0035100535167104387,\n",
       "    -0.013956165773793149,\n",
       "    0.04770819967812812,\n",
       "    0.0059356480393463786,\n",
       "    0.010137484493351433,\n",
       "    -0.0014340955314856563,\n",
       "    0.0010070774850032833,\n",
       "    -0.0008578866779046405,\n",
       "    -0.013018842665584531,\n",
       "    0.004530905899259242,\n",
       "    -0.0008974387491493601,\n",
       "    -0.0054166031407520444,\n",
       "    0.005529270241224175,\n",
       "    0.0016056970677933574,\n",
       "    0.004550104303070616,\n",
       "    -0.002150649335464016,\n",
       "    -0.012316736519209696,\n",
       "    -0.029587299859038897,\n",
       "    -0.0012561962659881389,\n",
       "    -0.005240947164266959,\n",
       "    -0.01355004584813937,\n",
       "    0.004135895391520081,\n",
       "    0.010776441097077712,\n",
       "    -0.01881505019688742,\n",
       "    0.005480704595442248,\n",
       "    0.0022941158270550726,\n",
       "    -0.000724678990233843,\n",
       "    -0.011112855878424692,\n",
       "    0.0062292575019063075,\n",
       "    -0.0016421537880169387,\n",
       "    -0.006031942756359348,\n",
       "    -0.008078983265461826,\n",
       "    -0.004033354822005279,\n",
       "    -0.01997992057562284,\n",
       "    -0.00243420580101269,\n",
       "    -0.006169344963856516,\n",
       "    -0.00224832810236611,\n",
       "    0.037348443219394976,\n",
       "    0.016933098936950584,\n",
       "    -0.019046887619144776,\n",
       "    0.013472962126366898,\n",
       "    0.014727223593356101,\n",
       "    -0.00797802669773061,\n",
       "    0.012846290728206677,\n",
       "    0.005364302877092439,\n",
       "    0.006745828436506689,\n",
       "    0.00536139173867936,\n",
       "    -0.0014943428756358102,\n",
       "    0.016756536881225855,\n",
       "    0.006298080238860213,\n",
       "    -0.003127009651380542,\n",
       "    -0.003253113317697676,\n",
       "    -0.0015913245810216929,\n",
       "    -0.015991302345803392,\n",
       "    -0.006963695919981419,\n",
       "    0.0030781314863277984,\n",
       "    0.003116388025430123,\n",
       "    0.005904571384958179,\n",
       "    0.0037389576396394584,\n",
       "    0.007928043760686676,\n",
       "    0.008401612446548532,\n",
       "    -0.007457341387750222,\n",
       "    0.006069774460643085,\n",
       "    0.0035078041838120287,\n",
       "    -0.01723077845306001,\n",
       "    -0.01060425380748724,\n",
       "    0.01812863196388466,\n",
       "    -0.01762605665458231,\n",
       "    0.0008599388919801408,\n",
       "    -0.0066457230493841436,\n",
       "    -0.009706817324795123,\n",
       "    -0.0023878406333841776,\n",
       "    0.0032841307923690004,\n",
       "    -0.01612023455075856,\n",
       "    -0.013546921159088376,\n",
       "    -0.013980801660356701,\n",
       "    0.0016476446584285972,\n",
       "    0.012655859968789469,\n",
       "    0.014347193108843756,\n",
       "    0.026375204129021487,\n",
       "    0.022867046629708284,\n",
       "    -0.05980683854253874,\n",
       "    0.0017345153203149708,\n",
       "    0.0073506174418238234,\n",
       "    -0.008482938472620894,\n",
       "    0.009555538858747999,\n",
       "    0.013659615457047412,\n",
       "    0.007294415346107795,\n",
       "    -0.011440275342806693,\n",
       "    0.0005207970589138493,\n",
       "    -0.016990251937393928,\n",
       "    0.010025557768911694,\n",
       "    -0.009699153677374117,\n",
       "    0.0003369075469256825,\n",
       "    0.003321203485305245,\n",
       "    0.004784882579513777,\n",
       "    -0.007498979732886218,\n",
       "    0.015240907565087319,\n",
       "    0.01230148275831376,\n",
       "    0.006590006982832236,\n",
       "    -0.010180485734775627,\n",
       "    0.008138308539257353,\n",
       "    -0.008363596403742443,\n",
       "    -0.007666116852084312,\n",
       "    0.0005701263748720454,\n",
       "    -0.0002649091885899838,\n",
       "    -0.021066746254715166,\n",
       "    -0.004916014255308033,\n",
       "    -0.007478634501710384,\n",
       "    -0.013866387876836724,\n",
       "    -0.006092959814571749,\n",
       "    0.005204555919474814,\n",
       "    0.009766704176329504,\n",
       "    0.01668457333819168,\n",
       "    0.008707114262085903,\n",
       "    0.010056074356532533,\n",
       "    0.011785385261448377,\n",
       "    0.01830573796934747,\n",
       "    -0.01320214365417552,\n",
       "    0.002274800071124279,\n",
       "    0.0003717130586127365,\n",
       "    0.003970424118394869,\n",
       "    -0.02559314945892027,\n",
       "    0.0029729248076106386,\n",
       "    0.004130452368539087,\n",
       "    -0.01020582271211271,\n",
       "    0.014000899595864574,\n",
       "    -0.011149960301762326,\n",
       "    0.02031356524256291,\n",
       "    -0.007760981686406151,\n",
       "    -0.026360543676265794,\n",
       "    -0.032529243958951244,\n",
       "    0.035446464535953355,\n",
       "    0.00509886195245062,\n",
       "    -0.0011195800154967855,\n",
       "    -0.014562975955312996,\n",
       "    0.0038110554073080777,\n",
       "    -0.040938962767568726,\n",
       "    -0.003872714628405717,\n",
       "    0.014282343219606523,\n",
       "    0.007493938124665644,\n",
       "    0.007240429341917294,\n",
       "    0.013190204964738907,\n",
       "    -0.02468445724590713,\n",
       "    0.004831339412746299,\n",
       "    0.017087999705327612,\n",
       "    0.0036252227859777555,\n",
       "    -0.014011432074496807,\n",
       "    0.009459973940966959,\n",
       "    0.008538996522387765,\n",
       "    -0.021095392259625596,\n",
       "    -0.006016478466768487,\n",
       "    -0.002927395207218683,\n",
       "    -0.0052458160180799745,\n",
       "    -0.019099104779372173,\n",
       "    -0.006241768345882238,\n",
       "    0.0003802451683788801,\n",
       "    -0.013810548414279419,\n",
       "    0.0037657340691538053,\n",
       "    0.05097315120565802,\n",
       "    0.0017282747562133698,\n",
       "    -0.0036437525849027344,\n",
       "    0.007086487033125055,\n",
       "    0.012910844467030953,\n",
       "    0.004784004705075369,\n",
       "    -0.01577889702428192,\n",
       "    0.004730700652686133,\n",
       "    -0.005992487261375996,\n",
       "    -0.001350534652658374,\n",
       "    0.02254481080486736,\n",
       "    -0.021443479799426124,\n",
       "    0.006122753654160967,\n",
       "    -0.012320252046220646,\n",
       "    0.006459609135527228,\n",
       "    0.0066514869019791735,\n",
       "    -0.01114107578937362,\n",
       "    0.042770477799013225,\n",
       "    0.0029959429473605573,\n",
       "    -0.00010027176711911095,\n",
       "    -0.004251541875951133,\n",
       "    0.012665077902221331,\n",
       "    -0.044747932530556984,\n",
       "    -0.005061420582469674,\n",
       "    -0.018343909138560346,\n",
       "    -0.01385769072491336,\n",
       "    0.00286113709254841,\n",
       "    0.0009604499119918621,\n",
       "    -0.013608608081330084,\n",
       "    0.011985231387906086,\n",
       "    0.017063300357961282,\n",
       "    0.003156337356263652,\n",
       "    0.010709087024416633,\n",
       "    0.006825235025123647,\n",
       "    -0.01696784322281353,\n",
       "    -0.017623040755478936,\n",
       "    0.010183228651695632,\n",
       "    0.0017774542341650104,\n",
       "    0.001701970631205401,\n",
       "    0.006034805543684596,\n",
       "    -0.011440020492281256,\n",
       "    0.016430575000679053,\n",
       "    -0.003633690270233929,\n",
       "    -0.012771185371777903,\n",
       "    0.00582186936751133,\n",
       "    0.022729689247698793,\n",
       "    0.013450735735680189,\n",
       "    -0.01298059796242558,\n",
       "    -0.037449621899935906,\n",
       "    -0.003939549430529792,\n",
       "    -0.0031976787955009436,\n",
       "    -0.020105830837588653,\n",
       "    0.005286480290259068,\n",
       "    -0.0009818970191301896,\n",
       "    0.008486704820899962,\n",
       "    -0.001813614803975635,\n",
       "    -0.011894207443123719,\n",
       "    -0.010167846961879815,\n",
       "    -0.01851018047109199,\n",
       "    0.006459690224330776,\n",
       "    0.004425145953146447,\n",
       "    -0.03045611652699316,\n",
       "    -0.01646589144108132,\n",
       "    -0.015473381610001096,\n",
       "    -0.0035746213579353325,\n",
       "    -0.013086970355650884,\n",
       "    -0.03169035258510624,\n",
       "    -0.005371105270761478,\n",
       "    0.03004892381157816,\n",
       "    -0.010198975996613163,\n",
       "    -0.004165293860234859,\n",
       "    0.002146790566095192,\n",
       "    0.014397060204739767,\n",
       "    0.015945573297174137,\n",
       "    -0.004313744039472526,\n",
       "    -0.014614011535831556,\n",
       "    -0.023600083369893502,\n",
       "    0.015513634897933639,\n",
       "    -0.008266075785190126,\n",
       "    0.018897696308388966,\n",
       "    0.027030977845483528,\n",
       "    -0.004612158895042695,\n",
       "    -0.003209894244549665,\n",
       "    -0.01842449629957181,\n",
       "    -0.01074663265143071,\n",
       "    0.0037058474694480056,\n",
       "    -0.008404088928828308,\n",
       "    -0.0012002215714820594,\n",
       "    -0.0030247448341635193,\n",
       "    -0.002036259097916497,\n",
       "    -0.0032907493511728533,\n",
       "    -0.010711506593436776,\n",
       "    0.0063334928777809725,\n",
       "    0.007689381783845027,\n",
       "    -0.019144363412209417,\n",
       "    0.009297080133383085,\n",
       "    0.002450226883599339,\n",
       "    0.020932344332949264,\n",
       "    0.004457163439118666,\n",
       "    0.02856509540883094,\n",
       "    0.002232007595594932,\n",
       "    0.002393772707472282,\n",
       "    0.0011181003966606224,\n",
       "    -0.009194858882510827,\n",
       "    -0.01047311860609283,\n",
       "    0.006502681896268838,\n",
       "    -0.02563438890758167,\n",
       "    -0.011528087969505706,\n",
       "    -0.0035814109083466663,\n",
       "    -0.005908363419752655,\n",
       "    -0.0015387708518938546,\n",
       "    -0.00970363924808465,\n",
       "    0.0280576164933712,\n",
       "    0.005275369613201539,\n",
       "    -0.01676374119331248,\n",
       "    -0.016249241296974134,\n",
       "    0.017558588755401967,\n",
       "    0.007604395177498226,\n",
       "    0.008417952092291976,\n",
       "    0.007398820454447028,\n",
       "    0.003931649819727035,\n",
       "    0.009752431539590779,\n",
       "    0.013939442341290057,\n",
       "    0.03285110506286149,\n",
       "    0.0019102139817447816,\n",
       "    0.012203615119974831,\n",
       "    -0.0021532990758085157,\n",
       "    0.03104122915784944,\n",
       "    -0.019745256629356108,\n",
       "    0.012262133031335037,\n",
       "    -0.008668782929894592,\n",
       "    0.001174691441622239,\n",
       "    -0.0204796250390853,\n",
       "    -0.00206207266084586,\n",
       "    -0.025005927511857422,\n",
       "    0.019550494418320824,\n",
       "    -0.0062844487576923964,\n",
       "    0.008392703758615913,\n",
       "    3.096256226847556e-05,\n",
       "    0.011824858888089665,\n",
       "    -0.024511124639923696,\n",
       "    0.01118227192351884,\n",
       "    -0.028999245870339647,\n",
       "    -0.023724589435683594,\n",
       "    -0.020222246154681912,\n",
       "    -0.002275099243480225,\n",
       "    0.005950805098066655,\n",
       "    -0.0070019839376565494,\n",
       "    -0.005302042792997083,\n",
       "    -0.008516640188152515,\n",
       "    0.0024970503792479037,\n",
       "    0.010336485483086452,\n",
       "    0.007353875600023513,\n",
       "    -0.003857476229053311,\n",
       "    -0.0007034380677473932,\n",
       "    0.002663324733722536,\n",
       "    0.012398832637087178,\n",
       "    -0.009167581817774577,\n",
       "    0.0013796834333336559,\n",
       "    -0.015415802515596252,\n",
       "    -0.004818637682704875,\n",
       "    0.008755028175496461,\n",
       "    -0.003523890238172949,\n",
       "    0.02332388180992375,\n",
       "    -0.0010350646433848862,\n",
       "    0.0009677349980963045,\n",
       "    0.003114853382048696,\n",
       "    -0.01126664356446731,\n",
       "    -0.0010214289440883138,\n",
       "    -0.01980846963280744,\n",
       "    -0.0017521323665428733,\n",
       "    0.016837865425584044,\n",
       "    -0.006145357284064179,\n",
       "    0.009126633482954482,\n",
       "    -0.00638955898606248,\n",
       "    -0.0015844039538331957,\n",
       "    -0.022346831231862742,\n",
       "    -0.015129573141473493,\n",
       "    -0.01998811809963863,\n",
       "    -0.017090507918008778,\n",
       "    -0.008426936832456494,\n",
       "    -0.013706127188910908,\n",
       "    0.0065789214886329515,\n",
       "    -0.009495741658188969,\n",
       "    -0.011004000455376467,\n",
       "    0.006497732960966604,\n",
       "    0.011524935075653478,\n",
       "    0.018478147875404825,\n",
       "    0.017961611189491654,\n",
       "    0.0014546277453839566,\n",
       "    -0.01873524068253855,\n",
       "    0.01898100926197683,\n",
       "    -0.006768644106076321,\n",
       "    -0.002160055133018384,\n",
       "    0.026175578604402,\n",
       "    0.039915531408507086,\n",
       "    0.003561091111857659,\n",
       "    0.010932123541374654,\n",
       "    0.006703849115470061,\n",
       "    0.01268490990674614,\n",
       "    0.008603953186943954,\n",
       "    0.02344228758013267,\n",
       "    -0.013930954710747288,\n",
       "    0.010011938879173,\n",
       "    -0.0013436307720706094,\n",
       "    0.014479924903450877,\n",
       "    0.002990582020497441,\n",
       "    -0.018604531575105637,\n",
       "    -0.02146988150800979,\n",
       "    -0.008975677357492893,\n",
       "    0.0015430363244233296,\n",
       "    -0.0010672070992911438,\n",
       "    0.026548760358786134,\n",
       "    0.014759490893282106,\n",
       "    0.009103121759182969,\n",
       "    0.009809532159688977,\n",
       "    -0.005829698718139585,\n",
       "    0.023085136225992734,\n",
       "    0.01567071750914898,\n",
       "    0.030465188399847205,\n",
       "    -0.005229561490397398,\n",
       "    4.950612323200297e-05,\n",
       "    -0.028573641463604835,\n",
       "    0.00925131381412363,\n",
       "    -0.01024834447191593,\n",
       "    0.002435872906228484,\n",
       "    -0.0011042721114556241,\n",
       "    -0.0010058388031633757,\n",
       "    -0.01702483706759277,\n",
       "    0.0017705647078064455,\n",
       "    0.005662902071184958,\n",
       "    0.009732572337579067,\n",
       "    -0.009129955605614115,\n",
       "    -0.01068336021643392,\n",
       "    0.00018686012916456225,\n",
       "    -0.011921437164086468,\n",
       "    0.004362446176346141,\n",
       "    -0.006033786645240019,\n",
       "    -0.013624603225572742,\n",
       "    -0.009166583569273759,\n",
       "    0.006972036482632039,\n",
       "    -0.005155930842147428,\n",
       "    0.01173363045849835,\n",
       "    -0.012584456492522654,\n",
       "    0.008878181418141654,\n",
       "    0.11624329198127763,\n",
       "    0.005107996782450276,\n",
       "    0.001930652515410412,\n",
       "    0.003986655729676444,\n",
       "    -0.004601020013183932,\n",
       "    0.013583777783100883,\n",
       "    -0.025500025263760297,\n",
       "    0.00027841066325211245,\n",
       "    0.010283554136999237,\n",
       "    0.004142067206418674,\n",
       "    -0.014471918769157745,\n",
       "    0.012552247616827775,\n",
       "    -0.00894657806113406,\n",
       "    0.0008273744343268489,\n",
       "    -0.007095378093056903,\n",
       "    -0.021533594139368697,\n",
       "    0.017642610858278,\n",
       "    -0.02249821848785748,\n",
       "    0.007671428420545268,\n",
       "    -0.013403613571332844,\n",
       "    -0.00653283534707379,\n",
       "    0.004103773144857565,\n",
       "    -0.01933612785579926,\n",
       "    0.00313623010309823,\n",
       "    0.011610702854263029,\n",
       "    -0.008003115875742567,\n",
       "    0.01572026125714513,\n",
       "    -0.005682281287918528,\n",
       "    0.001585259667356348,\n",
       "    0.007440847119257157,\n",
       "    -0.004167854453261172,\n",
       "    0.012890905687187188,\n",
       "    -0.00015159084366436063,\n",
       "    -0.0021499132405175254,\n",
       "    0.02107291706229943,\n",
       "    -0.0010240057171010495,\n",
       "    0.024871739140729432,\n",
       "    0.002051630966417599,\n",
       "    -0.007926909021094173,\n",
       "    0.003065982268196261,\n",
       "    -0.002385202728983053,\n",
       "    0.009449725524975727,\n",
       "    -0.007704419475817224,\n",
       "    -0.004641769907081057,\n",
       "    0.009336668593857969,\n",
       "    -0.019925160954027063,\n",
       "    0.014857034176406844,\n",
       "    -0.0048830841425530295,\n",
       "    0.008531615930293428,\n",
       "    -0.019167388603159644,\n",
       "    -0.01704915363551378,\n",
       "    0.009940159674661175,\n",
       "    0.0009475227324120022,\n",
       "    0.005086111871321365,\n",
       "    -0.012812613188218972,\n",
       "    -0.0015870892020078203,\n",
       "    -0.012226627215838773,\n",
       "    -0.00017861373466449034,\n",
       "    0.005205411632997966,\n",
       "    -0.001104400040375507,\n",
       "    -0.004761852855649066,\n",
       "    -0.009318709186672231,\n",
       "    0.026011223183725608,\n",
       "    -0.012378009435261862,\n",
       "    0.006841752965503462,\n",
       "    -0.003628684421672062,\n",
       "    0.015851707718667445,\n",
       "    -0.004080422087721652,\n",
       "    -0.010353723653212065,\n",
       "    0.010302699153151131,\n",
       "    -0.019049639601893747,\n",
       "    -0.01512382339127908,\n",
       "    0.016205832093246376,\n",
       "    -0.0062106171502336344,\n",
       "    -0.021942227314275288,\n",
       "    -0.03768885502400254,\n",
       "    0.013066252921830194,\n",
       "    -0.011066671523718376,\n",
       "    -0.018265362796381024,\n",
       "    -0.018655483548534826,\n",
       "    0.0045434892698669165,\n",
       "    0.003080310055394541,\n",
       "    -0.025914855436423728,\n",
       "    0.006485792256901332,\n",
       "    0.01035341440771282,\n",
       "    0.0016890122878384633,\n",
       "    -0.01416420237306634,\n",
       "    -0.0026005614961194527,\n",
       "    -0.018684220211734937,\n",
       "    0.002733624193483907,\n",
       "    -0.0061981037879718795,\n",
       "    0.0031879682853618156,\n",
       "    -0.0026314973783300648,\n",
       "    0.009964056192506666,\n",
       "    -0.0009333718547928902,\n",
       "    -0.017266507892337486,\n",
       "    -0.01012502300777766,\n",
       "    -0.0002700856824950309,\n",
       "    0.009848711650545966,\n",
       "    0.004582224031447308,\n",
       "    0.0010128870444860276,\n",
       "    -0.005443557864902764,\n",
       "    0.007208029580156921,\n",
       "    0.026891781107507846,\n",
       "    -0.03153565730885249,\n",
       "    0.02564320290796729,\n",
       "    0.013369953155688745,\n",
       "    0.006526731525892457,\n",
       "    -0.02782322250734485,\n",
       "    -0.0037215731571074453,\n",
       "    0.015641989911777843,\n",
       "    -0.018762319306351832,\n",
       "    0.005928748439844516,\n",
       "    -0.009215514870157399,\n",
       "    -0.0045705014109344334,\n",
       "    -0.0013385434569623213,\n",
       "    0.002219555679507294,\n",
       "    0.01375017704455241,\n",
       "    -0.0054303967995269565,\n",
       "    0.012459139538697081,\n",
       "    0.03723011601970378,\n",
       "    0.015579030751537616,\n",
       "    0.002130521180526251,\n",
       "    0.02484663888225985,\n",
       "    0.005634158860441706,\n",
       "    0.018481993801515943,\n",
       "    -0.02921975302101558,\n",
       "    0.009555885374877445,\n",
       "    0.0038897274119500396,\n",
       "    -0.003079571190333644,\n",
       "    -0.02087367028786794,\n",
       "    0.001993935401293373,\n",
       "    0.004563901991102847,\n",
       "    0.010636136313339267,\n",
       "    -0.012712065086448485,\n",
       "    0.033698568681652975,\n",
       "    0.0025128687398256835,\n",
       "    -0.01177853250206285,\n",
       "    0.017204421066306853,\n",
       "    -0.0071036692973053634,\n",
       "    0.011334226297481249,\n",
       "    -0.02351249134503271,\n",
       "    0.019754481613988278,\n",
       "    0.012159638798279405,\n",
       "    -0.003623659182309347,\n",
       "    -0.012409924175172442,\n",
       "    -0.0025506112967912356,\n",
       "    -0.0004991369362733449,\n",
       "    0.013681727013900524,\n",
       "    -0.01625056692263213,\n",
       "    0.010814105587182704,\n",
       "    -0.014778146354669727,\n",
       "    0.00034382505773547186,\n",
       "    -0.013096667770703726,\n",
       "    0.0005613358575017391,\n",
       "    0.016962057209303244,\n",
       "    -0.0033357803309715653,\n",
       "    -0.0188541480952837,\n",
       "    -0.01205636893318984,\n",
       "    -0.012385912823493356,\n",
       "    -0.048819480934518975,\n",
       "    -0.013464303252388064,\n",
       "    -0.015757232714991232,\n",
       "    -0.014925141720186602,\n",
       "    -0.005059240250602853,\n",
       "    0.0043455384053206975,\n",
       "    -0.012682908373172857,\n",
       "    -0.010696453288092468,\n",
       "    0.06141780411610545,\n",
       "    0.005292868677738565,\n",
       "    0.01239742038239682,\n",
       "    -0.0012829519196444338,\n",
       "    -0.015434345157778936,\n",
       "    0.005713883760386875,\n",
       "    0.015920044930114393,\n",
       "    0.016087682180877225,\n",
       "    -0.015250876955009202,\n",
       "    0.01852766140397108,\n",
       "    0.0003515410855016255,\n",
       "    0.02661772311243188,\n",
       "    0.006783548328899821,\n",
       "    0.014078637064637077,\n",
       "    0.014301639332907887,\n",
       "    -0.019990507449228877,\n",
       "    -0.007062756722143977,\n",
       "    0.0014566584910728033,\n",
       "    0.029692249924430543,\n",
       "    -0.0007998213654642377,\n",
       "    0.0004701442578406069,\n",
       "    -0.009158061690043778,\n",
       "    0.0038115056768134917,\n",
       "    -0.021635068970322587,\n",
       "    0.006862676395104593,\n",
       "    -0.016281997144350087,\n",
       "    -0.004893950042228421,\n",
       "    -0.019863591887561937,\n",
       "    -0.00530782175530706,\n",
       "    0.0014635135169155731,\n",
       "    -0.04662617082987423,\n",
       "    -0.006897427228510683,\n",
       "    -0.015815479658796726,\n",
       "    0.007172366119968045,\n",
       "    -0.01588612362005888,\n",
       "    -0.003719895978748353,\n",
       "    -0.013795798310548375,\n",
       "    -0.013121300635324289,\n",
       "    0.028736147455171744,\n",
       "    -0.005978659353913871,\n",
       "    -0.0011919307449764721,\n",
       "    -0.0067760755675443105,\n",
       "    0.0012679514983024393,\n",
       "    -0.018228954427245272,\n",
       "    -0.01189621502058298,\n",
       "    -0.021134975683528828,\n",
       "    0.002477096993346356,\n",
       "    0.002439988792579986,\n",
       "    0.026903365222300375,\n",
       "    -0.007093168045417354,\n",
       "    -0.043452103230434865,\n",
       "    0.013725218817403325,\n",
       "    -0.0037723924168736847,\n",
       "    -0.0035321925228790378,\n",
       "    0.01048632953352796,\n",
       "    -0.0037478769043725406,\n",
       "    0.0025272330421684188,\n",
       "    -0.00020980509697199394,\n",
       "    0.012204640565962552,\n",
       "    -0.007823685996120941,\n",
       "    -0.00020091734229029057,\n",
       "    -0.0005653474868201082,\n",
       "    -0.012643407549044665,\n",
       "    0.022125546434524215,\n",
       "    0.01602627025544755,\n",
       "    0.0008224909114989052,\n",
       "    0.004832335142961292,\n",
       "    -0.002380918621138477,\n",
       "    -0.007408684076364283,\n",
       "    0.009827027194968684,\n",
       "    -0.0016417997170300193,\n",
       "    0.0008089637503213671,\n",
       "    -0.0034701072078198994,\n",
       "    0.0015209418919138237,\n",
       "    -0.022292875447102133,\n",
       "    0.015680533787292738,\n",
       "    -0.007723913022727224,\n",
       "    0.006929016605892743,\n",
       "    -0.018129292762084998,\n",
       "    0.013070138133200175,\n",
       "    0.0054993106984277075,\n",
       "    0.0024740138560114663,\n",
       "    0.011145680223175069,\n",
       "    0.004117536080545418,\n",
       "    0.011279096991526441,\n",
       "    0.02091697271627674,\n",
       "    -0.004868349148536933,\n",
       "    0.010454774404833113,\n",
       "    -0.005730519556543276,\n",
       "    -0.012387377458528864,\n",
       "    0.01201526043539131,\n",
       "    -0.011080627863757549,\n",
       "    0.03967285326943259,\n",
       "    -0.012310292729442061,\n",
       "    0.0008724040290683573,\n",
       "    -0.007572977547209394,\n",
       "    0.02099666538216336,\n",
       "    -0.0032661308407814886,\n",
       "    0.01291072157468272,\n",
       "    -0.004193401959293181,\n",
       "    0.027529701184788775,\n",
       "    -0.005779353147936927,\n",
       "    0.0066150311890699216,\n",
       "    -0.0012098684949041199,\n",
       "    -0.002143114372448641,\n",
       "    0.0809581266743241,\n",
       "    0.014362182953385288,\n",
       "    0.015971934713184612,\n",
       "    0.04171613397779914,\n",
       "    -0.011898121866609263,\n",
       "    -0.010581550957122545,\n",
       "    -0.015250380349044617,\n",
       "    -0.0028722560799491603,\n",
       "    -0.0031566239371904757,\n",
       "    0.005794310758419905,\n",
       "    -0.023754444217789765,\n",
       "    -0.007304894437080549,\n",
       "    -0.008389814277460925,\n",
       "    0.00682367268059815,\n",
       "    -0.01086362415232061,\n",
       "    0.017531274420035513,\n",
       "    0.005662922721128718,\n",
       "    0.019312611095456098,\n",
       "    0.015218762766861323,\n",
       "    0.001795562849785848,\n",
       "    -0.02646246172552479,\n",
       "    0.008489160653235978,\n",
       "    -0.002095003780915194,\n",
       "    0.0006249009802684771,\n",
       "    -0.012236775907711356,\n",
       "    0.002829942582383626,\n",
       "    -0.003121018901232728,\n",
       "    0.009960764289276927,\n",
       "    -0.0024326935703751,\n",
       "    0.02671158869093857,\n",
       "    0.0009519889752788323,\n",
       "    -0.02773857184032703,\n",
       "    0.0004185970875568065,\n",
       "    0.00424412955345541,\n",
       "    0.022321450940009476,\n",
       "    -0.007244085389277248,\n",
       "    -0.004701248292654712,\n",
       "    5.549357993413745e-05,\n",
       "    -0.017073981919114325,\n",
       "    0.005175733634556673,\n",
       "    -0.01488568723251758,\n",
       "    0.003645221249195561,\n",
       "    -0.012787115040589122,\n",
       "    0.006841462858976484,\n",
       "    0.013376178358246817,\n",
       "    -0.006100482941643748,\n",
       "    0.0016753492021835499,\n",
       "    -0.011377274882678944,\n",
       "    0.01592920645394379,\n",
       "    0.00362876349584695,\n",
       "    0.014849668694027455,\n",
       "    -0.005464474243303586,\n",
       "    -0.015313751500845726,\n",
       "    -0.018483254959056835,\n",
       "    -0.001435666941840121,\n",
       "    0.004448940732244631,\n",
       "    0.003373450361305373,\n",
       "    0.01284500740975053,\n",
       "    -0.0014716814510729267,\n",
       "    -0.001251128341680699,\n",
       "    -0.013311103837914041,\n",
       "    0.00027755731062192044,\n",
       "    0.003673214766248871,\n",
       "    0.011524645976440831,\n",
       "    0.0019214738672374103,\n",
       "    -0.028357584627637895,\n",
       "    0.005668648799436382,\n",
       "    0.02452497521195824,\n",
       "    -0.007326007241775679,\n",
       "    -0.0006606809741338799,\n",
       "    0.0036546305723500834,\n",
       "    -0.008826283576556798,\n",
       "    -0.01044991612782056,\n",
       "    0.0007068153408665801,\n",
       "    -0.005984913264930342,\n",
       "    0.014043105058968238,\n",
       "    0.0026599915306052776,\n",
       "    0.008162626114492694,\n",
       "    0.015805923267750054,\n",
       "    -0.014054371869746885,\n",
       "    0.026836358673083073,\n",
       "    0.012982822112465747,\n",
       "    -0.005556365485723899,\n",
       "    0.008496827322599971,\n",
       "    0.023714492116841828,\n",
       "    0.0006126019870875295,\n",
       "    0.008945291720734924,\n",
       "    0.004006456255628446,\n",
       "    -0.0014910378773197856,\n",
       "    -0.0028850318475938243,\n",
       "    -0.01948077013504176,\n",
       "    -0.015364544318610809,\n",
       "    -0.0005285668520823553,\n",
       "    0.036597409801393824,\n",
       "    0.001000181348144429,\n",
       "    -0.0003797351525422808,\n",
       "    -0.012593882940020782,\n",
       "    0.006246902627021152,\n",
       "    -0.02615570227804668,\n",
       "    0.009739040302890616,\n",
       "    0.0159524069175874,\n",
       "    -0.0027254835827277488,\n",
       "    -0.006880312958047635,\n",
       "    0.035204753418635444,\n",
       "    0.0097226643938313,\n",
       "    -0.01677202937561795,\n",
       "    -0.01636319977441705,\n",
       "    0.02035415598079593,\n",
       "    0.012272140699201451,\n",
       "    -0.0036517700514820763,\n",
       "    0.00851463865457923,\n",
       "    0.0025650662574236514,\n",
       "    -0.01771206316668802,\n",
       "    -0.022575425101978186,\n",
       "    -0.007544723387573253,\n",
       "    0.0027428942554323364,\n",
       "    0.005255877577263033,\n",
       "    -0.004776203055591184,\n",
       "    0.008930206181332064,\n",
       "    0.0025062675571940196,\n",
       "    -0.017453697114241447,\n",
       "    -0.033958246257356925,\n",
       "    -0.016688579427281237,\n",
       "    0.00921940008152738,\n",
       "    0.021208302122851203,\n",
       "    0.020916126572239725,\n",
       "    0.0035166005561968767,\n",
       "    0.009394141920258186,\n",
       "    0.0007921721352295779,\n",
       "    0.01419354141023566,\n",
       "    0.0027500416542593263,\n",
       "    -0.0035810044570145977,\n",
       "    -0.011302089948418116,\n",
       "    0.00018570302404608086,\n",
       "    0.013062684007159766,\n",
       "    0.015616257059909152,\n",
       "    0.012138090330136643,\n",
       "    -0.012328850481339691,\n",
       "    -0.0018982225342201464,\n",
       "    -0.0010902728346431447,\n",
       "    -0.017608855755086902,\n",
       "    0.0036464390922202714,\n",
       "    4.494733336112378e-05,\n",
       "    -0.018275810660609557,\n",
       "    0.002057335261552881,\n",
       "    -0.004618490369262559,\n",
       "    0.007141595689136101,\n",
       "    -0.06909963557539157,\n",
       "    -0.019512945769363754,\n",
       "    0.017222586972930196,\n",
       "    0.011952354662810562,\n",
       "    0.01191725983156085,\n",
       "    0.005115394498888217,\n",
       "    0.027691902967428086,\n",
       "    -0.00872681934500516,\n",
       "    -0.0030866790520731897,\n",
       "    -0.01693437621152075,\n",
       "    0.0027532164571982265,\n",
       "    -0.005263713475434431,\n",
       "    0.004277891204189651,\n",
       "    -0.0014184387189435156,\n",
       "    -0.01710769270047491,\n",
       "    0.015292138564585857,\n",
       "    0.01886033904915456,\n",
       "    -0.02424680938904541,\n",
       "    -0.005734805175359347,\n",
       "    0.003640188706803955,\n",
       "    0.01407787150574644,\n",
       "    -0.013357684067151963,\n",
       "    0.012800846749532753,\n",
       "    0.016174268906036893,\n",
       "    -0.006778819491778645,\n",
       "    -0.012905406984278774,\n",
       "    0.007273637473427318,\n",
       "    -0.015692634654336447,\n",
       "    0.014429966141950856,\n",
       "    0.00819385588065902,\n",
       "    -0.006113705956850837,\n",
       "    -0.010605633828119045,\n",
       "    0.007827412051826816,\n",
       "    -0.03459124661145119,\n",
       "    0.012979178656534914,\n",
       "    -0.011304627373214844,\n",
       "    0.01068092956695615,\n",
       "    -0.001343316238171134,\n",
       "    0.005694747306406784,\n",
       "    -0.00027845306488968186,\n",
       "    0.0006601783872404627,\n",
       "    -0.011879359629902686,\n",
       "    -0.008386408044054756,\n",
       "    0.02079883892093687,\n",
       "    0.00012530691216084666,\n",
       "    -0.0018153520434516406,\n",
       "    0.006018631097491238,\n",
       "    0.018873982114437166,\n",
       "    0.0013857950612010444,\n",
       "    0.0013264302503180733,\n",
       "    -0.003269763719911858,\n",
       "    -0.004627159820041854,\n",
       "    0.015509460587351009,\n",
       "    -0.015897778246854496,\n",
       "    0.00029145708366576064,\n",
       "    0.01054735364294067,\n",
       "    0.005344319775418162,\n",
       "    0.005677067932604725,\n",
       "    0.027584726737367615,\n",
       "    0.017695031496000015,\n",
       "    0.003400418936028126,\n",
       "    -0.0002608733837276999,\n",
       "    0.0034065053810372697,\n",
       "    -0.01181241754880249,\n",
       "    0.0009685798200332661,\n",
       "    -0.011014967086484837,\n",
       "    ...],\n",
       "   'index': 0}],\n",
       " 'model': './llama-2-7b-chat.Q4_K_S.gguf',\n",
       " 'usage': {'prompt_tokens': 5, 'total_tokens': 5}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "llama2_chat = Llama(model_path=\"./llama-2-7b-chat.Q4_K_S.gguf\", embedding=True, verbose=False)\n",
    "\n",
    "embeddings = llama2_chat.create_embedding(\"Hello, world!\")\n",
    "\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "906474e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[\"data\"][0][\"embedding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fa73826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4096, 4096)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = llama2_chat.create_embedding([\"Hello, world!\", \"Goodbye, world!\"])\n",
    "\n",
    "len(embeddings[\"data\"]), len(embeddings[\"data\"][0][\"embedding\"]), len(embeddings[\"data\"][1][\"embedding\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fd1144",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this video, I explained how you can access **open source LLMs** on **Local Machine** using Python library **llama-cpp-python**. Its a wrapper around **llama.cpp** library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67edfd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
